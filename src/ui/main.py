#!/usr/bin/env python3
"""
Streamlit UIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

æ›¸ç±ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»ç”Ÿæˆã®Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
"""

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ ï¼ˆStreamlitå®Ÿè¡Œå ´æ‰€ã«ä¾å­˜ã—ãªã„ãŸã‚ï¼‰
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

import streamlit as st
from src.generators.veo3_sample import check_api_key, generate_video_from_upload
from src.generators.veo3_talking_video import generate_video as generate_talking_video
from src.generators.explainer_slideshow import (
    generate_explainer,
    build_narration_segments,
)
from src.generators.slideshow_generator import generate_slideshow
from src.generators.cover_card_generator import generate_cover_card
from src.generators.nanobana_client import NanobanaClient
from src.generators.gemini_text_to_image import (
    generate_images as gemini_generate_images,
)
from src.generators.video_concat import concat_videos
from src.generators.scenario_generator import ScenarioGenerator, BookInfo
from src.generators.opening_animation_generator import generate_opening_animation
from src.generators.video_overlay_generator import add_floating_overlay
from src.generators.video_frame_generator import add_video_frame
import os
from PIL import Image, ImageDraw, ImageFont
import re


def _get_bgm_library() -> dict:
    bgm_dir = PROJECT_ROOT / "BGM"
    items = {}
    if bgm_dir.exists():
        for f in bgm_dir.glob("*.mp3"):
            name = f.stem
            display_names = {
                "yoiyaminoseaside": "å®µé—‡ã®ã‚·ãƒ¼ã‚µã‚¤ãƒ‰",
                "natsuyasuminotanken": "å¤ä¼‘ã¿ã®æ¢æ¤œ",
                "neonpurple": "ãƒã‚ªãƒ³ãƒ‘ãƒ¼ãƒ—ãƒ«",
                "yume": "å¤¢",
            }
            items[display_names.get(name, name)] = str(f)
    return items


def _split_text_by_images(text: str, num_images: int) -> list[str]:
    """slideshow_app.split_text_by_images ã¨åŒç­‰ã®åˆ†å‰²ãƒ­ã‚¸ãƒƒã‚¯"""
    text_clean = (text or "").replace('\n', '')

    sentences = re.split(r'([ã€‚ï¼ï¼Ÿ\?])', text_clean)

    segments = []
    i = 0
    while i < len(sentences):
        if i + 1 < len(sentences) and sentences[i + 1] in 'ã€‚ï¼ï¼Ÿ?':
            segments.append(sentences[i] + sentences[i + 1])
            i += 2
        elif sentences[i].strip():
            segments.append(sentences[i])
            i += 1
        else:
            i += 1

    segments = [s.strip() for s in segments if s.strip()]

    if len(segments) < num_images:
        new_segments = []
        for seg in segments:
            parts = re.split(r'(ã€)', seg)
            temp = []
            j = 0
            while j < len(parts):
                if j + 1 < len(parts) and parts[j + 1] == 'ã€':
                    temp.append(parts[j] + parts[j + 1])
                    j += 2
                elif parts[j].strip():
                    temp.append(parts[j])
                    j += 1
                else:
                    j += 1
            new_segments.extend([s.strip() for s in temp if s.strip()])
        if new_segments:
            segments = new_segments

    if len(segments) != num_images and segments:
        if len(segments) < num_images:
            while len(segments) < num_images:
                max_idx = max(range(len(segments)), key=lambda k: len(segments[k]))
                longest = segments[max_idx]
                if len(longest) > 1:
                    mid = len(longest) // 2
                    segments[max_idx] = longest[:mid]
                    segments.insert(max_idx + 1, longest[mid:])
                else:
                    segments.append("")
        else:
            step = len(segments) / num_images
            new_segments = []
            for i in range(num_images):
                start = int(i * step)
                end = int((i + 1) * step)
                combined = ''.join(segments[start:end])
                new_segments.append(combined)
            segments = new_segments

    result = []
    for i in range(num_images):
        if i < len(segments) and segments[i].strip():
            result.append(segments[i].strip())
        else:
            result.append("...")

    return result


def main():
    """Streamlit UIã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""

    st.title("ğŸ“š æ›¸ç±ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»ç”Ÿæˆ")

    # API Keyç¢ºèª
    api_key_ok, message = check_api_key()
    if api_key_ok:
        st.success("âœ… API Keyè¨­å®šæ¸ˆã¿")
    else:
        st.error(f"âŒ {message}")
        st.stop()

    # åˆ©ç”¨é †: ã‚·ãƒŠãƒªã‚ª â†’ ç”»åƒç”Ÿæˆ â†’ ã‚¹ãƒ©ã‚¤ãƒ‰ä½œæˆ â†’ ã‚«ãƒãƒ¼ â†’ Veo3ç³» â†’ æœ€å¾Œã«é€£çµ
    (
        tab_scn,
        tab_img,
        tab_qs,
        tab_exp,
        tab_open,
        tab_overlay,
        tab_frame,
        tab_cov,
        tab_vsimple,
        tab_vtalk,
        tab_concat,
    ) = st.tabs(
        [
            "Scenario (ã‚·ãƒŠãƒªã‚ªç”Ÿæˆ)",
            "Text to Image",
            "Quick Slideshow",
            "Explainer Slideshow",
            "Opening Animation",
            "Overlay",
            "Frame",
            "Cover Card",
            "Veo3 ç”»åƒâ†’å‹•ç”» (Simple)",
            "Veo3 Talking Video (å£ãƒ‘ã‚¯)",
            "Concat Videos",
        ]
    )

    # --- Tab: Scenario ---
    with tab_scn:
        st.subheader("Scenarioï¼ˆãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸç¨¿ã®ç”Ÿæˆï¼‰")
        st.caption(
            "OpenAI APIã§çŸ­å°ºãƒ—ãƒ­ãƒ¢ç”¨ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã¾ã™ï¼ˆOPENAI_API_KEY å¿…è¦ï¼‰"
        )

        # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
        title = st.text_input("æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«", value="ã€Œè…¸ã¨è„³ã€ã®ç§‘å­¦")
        desc = st.text_area(
            "èª¬æ˜ï¼ˆè¦ç´„ï¼‰",
            value="è…¸ã¨è„³ã®ç›¸äº’ä½œç”¨ã¨å¥åº·ã¸ã®å½±éŸ¿ã‚’ã€æœ€æ–°ç ”ç©¶ã¨å®Ÿä¾‹ã§è§£èª¬ã™ã‚‹ã€‚",
        )
        colx, coly, colz = st.columns(3)
        with colx:
            target = st.text_input("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆèª­è€…", value="ä¸€èˆ¬èª­è€…")
        with coly:
            mood = st.selectbox(
                "é›°å›²æ°—", ["ã‚¨ãƒãƒ«ã‚®ãƒƒã‚·ãƒ¥", "è½ã¡ç€ã", "ä¿¡é ¼æ„Ÿ", "è¦ªã—ã¿"], index=0
            )
        with colz:
            length = st.slider(
                "ç›®æ¨™æ–‡å­—æ•°", min_value=40, max_value=120, value=60, step=5
            )
        model = st.text_input("OpenAIãƒ¢ãƒ‡ãƒ«", value="gpt-4o")

        if st.button("ğŸ“ ã‚·ãƒŠãƒªã‚ªã‚’ç”Ÿæˆ"):
            try:
                bi = BookInfo(
                    title=title.strip(),
                    description=desc.strip(),
                    target_audience=target.strip(),
                    mood=mood,
                )
                gen = ScenarioGenerator(model=model.strip())
                text = gen.generate_narration(
                    bi, language="ja", target_length=int(length)
                )
                st.success("âœ… ã‚·ãƒŠãƒªã‚ªç”Ÿæˆå®Œäº†")
                st.text_area("ç”Ÿæˆçµæœ", value=text, height=160)
                st.info("Explainerã‚¿ãƒ–ã«è²¼ã‚Šä»˜ã‘ã¦å­—å¹•/TTSã¤ãå‹•ç”»ã‚’ä½œã‚Œã¾ã™")
            except Exception as e:
                st.error(f"âŒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                st.exception(e)

    # --- Tab 1: æ—¢å­˜ã®ã‚·ãƒ³ãƒ—ãƒ«ç”Ÿæˆï¼ˆè¡¨ç´™ã®å‹•ããªã©ï¼‰ ---
    with tab_vsimple:
        st.subheader("Veo3 ç”»åƒâ†’å‹•ç”» (Simple)")

        uploaded_file = st.file_uploader(
            "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["png", "jpg", "jpeg"], key="uploader_simple"
        )
        if uploaded_file:
            st.image(uploaded_file, width=300)
            st.success(f"ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ: {uploaded_file.name}")

        prompt = st.text_area(
            "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            value="æœ¬ã®ã‚¿ã‚¤ãƒˆãƒ«ãŒæµ®ã‹ã³ä¸ŠãŒã‚‹",
            height=100,
            key="prompt_simple",
        )

        if st.button(
            "ğŸ¥ å‹•ç”»ã‚’ç”Ÿæˆ",
            disabled=(uploaded_file is None or not prompt.strip()),
            key="btn_simple",
        ):
            try:
                with st.spinner("â³ å‹•ç”»ã‚’ç”Ÿæˆä¸­... æ•°åˆ†ã‹ã‹ã‚Šã¾ã™"):
                    output_path = generate_video_from_upload(
                        uploaded_file=uploaded_file,
                        prompt=prompt,
                        output_dir=Path("data/output"),
                    )

                    st.success(f"âœ… å‹•ç”»ç”Ÿæˆå®Œäº†: {output_path}")

                if output_path.exists():
                    st.video(str(output_path))
                    with open(output_path, "rb") as video_file:
                        st.download_button(
                            label="ğŸ“¥ å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=video_file,
                            file_name=output_path.name,
                            mime="video/mp4",
                            key="dl_simple",
                        )
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                st.exception(e)

    # --- Tab 2: Talking Videoï¼ˆå£ãƒ‘ã‚¯é‡è¦–ï¼‰ ---
    with tab_vtalk:
        st.subheader("Veo3 Talking Videoï¼ˆå£ãƒ‘ã‚¯é‡è¦–ï¼‰")

        uploaded_talk = st.file_uploader(
            "äººç‰©ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["png", "jpg", "jpeg"], key="uploader_talk"
        )
        if uploaded_talk:
            st.image(uploaded_talk, width=300)
            st.success(f"ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ: {uploaded_talk.name}")

        default_talk_prompt = (
            "ã‚·ãƒ§ãƒƒãƒˆ: æ­£é¢ã®ãƒã‚¹ãƒˆã‚·ãƒ§ãƒƒãƒˆã€‚ã‚«ãƒ¡ãƒ©ã¯å›ºå®šã—ã€æºã‚Œã‚„éåº¦ãªã‚ºãƒ¼ãƒ ã¯é¿ã‘ã‚‹ã€‚\n"
            "è¢«å†™ä½“: å…¥åŠ›ç”»åƒã®äººç‰©ã€‚é¡”ã®é€ å½¢ãƒ»é«ªå‹ãƒ»è¡£æœã®ä¸€è²«æ€§ã‚’ä¿ã¤ã€‚è‡ªç„¶ãªç¬ãã¨å¾®ç´°ãªè¡¨æƒ…ã€‚\n"
            "å£ã®å‹•ã: ã‚»ãƒªãƒ•ã¨æ­£ç¢ºã«åŒæœŸã€‚éåº¦ãªé ­ã®æºã‚Œã‚’é¿ã‘ã‚‹ã€‚\n"
            "ä¼šè©±: ã€Œè¨˜æ†¶åŠ›ã®ä½ä¸‹ã€ä¸çœ ã€ã†ã¤ã€ç™ºé”éšœå®³ã€è‚¥æº€ã€é«˜è¡€åœ§ã€ç³–å°¿ç—…ã€æ„ŸæŸ“ç—‡ã®é‡ç—‡åŒ–â€¦â€¦ã™ã¹ã¦ã®ä¸èª¿ã¯è…¸ã‹ã‚‰å§‹ã¾ã‚‹!ã€\n"
            "ç™ºè©±ã‹ãª: ã€ŒããŠãã‚Šã‚‡ãã®ã¦ã„ã‹ã€ãµã¿ã‚“ã€ã†ã¤ã€ã¯ã£ãŸã¤ã—ã‚‡ã†ãŒã„ã€ã²ã¾ã‚“ã€ã“ã†ã‘ã¤ã‚ã¤ã€ã¨ã†ã«ã‚‡ã†ã³ã‚‡ã†ã€ã‹ã‚“ã›ã‚“ã—ã‚‡ã†ã®ã˜ã‚…ã†ã—ã‚‡ã†ã‹â€¦â€¦ã™ã¹ã¦ã®ãµã¡ã‚‡ã†ã¯ã¡ã‚‡ã†ã‹ã‚‰ã¯ã˜ã¾ã‚‹ï¼ã€\n"
            "è¡¨ç¤º: å­—å¹•ã¯è¡¨ç¤ºã—ãªã„ã€‚ãƒ•ãƒªãƒƒã‚«ãƒ¼ã‚„æ­ªã¿ã‚’é¿ã‘ã€å®Ÿå†™çš„ã§ã‚¯ãƒªã‚¢ãªè³ªæ„Ÿã€‚ç´„6ç§’ã€‚"
        )

        talk_prompt = st.text_area(
            "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ã¯è‡ªç”±ç·¨é›†å¯ãƒ»å­—å¹•ã¯å‡ºã—ã¾ã›ã‚“ï¼‰",
            value=default_talk_prompt,
            height=220,
            key="prompt_talk",
        )

        if st.button(
            "ğŸ™ï¸ Talking Video ã‚’ç”Ÿæˆ",
            disabled=(uploaded_talk is None or not talk_prompt.strip()),
            key="btn_talk",
        ):
            try:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦ã‹ã‚‰ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã¸æ¸¡ã™
                temp_dir = Path("temp")
                temp_dir.mkdir(exist_ok=True)
                temp_image = temp_dir / uploaded_talk.name
                with open(temp_image, "wb") as f:
                    f.write(uploaded_talk.getbuffer())

                with st.spinner("â³ Talking Video ã‚’ç”Ÿæˆä¸­... æ•°åˆ†ã‹ã‹ã‚Šã¾ã™"):
                    out = generate_talking_video(
                        image_path=temp_image,
                        prompt=talk_prompt,
                        output_dir=Path("data/output"),
                        model="veo-3.0-generate-001",
                        debug=False,
                    )

                st.success(f"âœ… å‹•ç”»ç”Ÿæˆå®Œäº†: {out}")
                if Path(out).exists():
                    st.video(str(out))
                    with open(out, "rb") as video_file:
                        st.download_button(
                            label="ğŸ“¥ å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=video_file,
                            file_name=Path(out).name,
                            mime="video/mp4",
                            key="dl_talk",
                        )
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                st.exception(e)

    # --- Tab 3: Explainer Slideshow ---
    with tab_qs:
        st.subheader("Quick Slideshowï¼ˆçŸ­ã„ã‚¹ãƒ©ã‚¤ãƒ‰ã‚·ãƒ§ãƒ¼ï¼‰")
        st.caption("ç”»åƒã‚’è¤‡æ•°é¸ã³ã€çŸ­å°ºã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚·ãƒ§ãƒ¼ã‚’ä¸€æ°—ã«ç”Ÿæˆã€‚å¿…è¦ãªã‚‰ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³/TTSã¨BGMã‚‚è¿½åŠ ã§ãã¾ã™ã€‚")

        qs_images = st.file_uploader(
            "ç”»åƒï¼ˆè¤‡æ•°ï¼‰",
            type=["png", "jpg", "jpeg"],
            accept_multiple_files=True,
            key="qs_imgs",
        )
        col1, col2, col3 = st.columns(3)
        with col1:
            qs_duration = st.slider(
                "å‹•ç”»ã®é•·ã•(ç§’)", min_value=4, max_value=60, value=12, step=1
            )
        with col2:
            qs_resolution = st.selectbox(
                "è§£åƒåº¦",
                ["ç¸¦(1080x1920)", "æ¨ª(1920x1080)", "æ­£æ–¹å½¢(1080x1080)"],
                index=0,
            )
        with col3:
            qs_pan = st.checkbox("æ¨ªãƒ‘ãƒ³åŠ¹æœ", value=True)
        qs_pan_scale = st.slider(
            "ãƒ‘ãƒ³å¹…",
            min_value=1.0,
            max_value=1.3,
            value=1.15,
            step=0.05,
            disabled=not qs_pan,
        )

        # ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ / BGMï¼ˆä»»æ„ï¼‰
        st.markdown("---")
        st.header("ğŸ¤ ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ / ğŸµ BGMï¼ˆä»»æ„ï¼‰")
        enable_narr = st.checkbox("ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ï¼ˆTTSã§èª­ã¿ä¸Šã’ï¼‰", value=False, key="qs_narr")
        narration_text = ""
        if enable_narr:
            narration_text = st.text_area(
                "ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆç”»åƒæšæ•°ã«åˆã‚ã›ã¦è‡ªå‹•åˆ†å‰²ï¼‰",
                height=150,
                placeholder="ä¾‹ï¼‰è…¸ã¨è„³ã¯åŒæ–¹å‘ã«ã¤ãªãŒã£ã¦ã„ã¾ã™ã€‚â€¦",
                key="qs_narr_text",
            )
            if narration_text:
                st.caption(f"æ–‡å­—æ•°: {len(narration_text)} æ–‡å­—")

        bgm_library = _get_bgm_library()
        bgm_choice = st.selectbox(
            "BGMã‚’é¸æŠï¼ˆä»»æ„ï¼‰",
            options=["ãªã—"] + list(bgm_library.keys()),
            index=0,
            key="qs_bgm",
        )
        selected_bgm_path = bgm_library.get(bgm_choice) if bgm_choice != "ãªã—" else None

        # è§£åƒåº¦ãƒãƒƒãƒ—
        res_map = {
            "ç¸¦(1080x1920)": (1080, 1920),
            "æ¨ª(1920x1080)": (1920, 1080),
            "æ­£æ–¹å½¢(1080x1080)": (1080, 1080),
        }
        qs_res_tuple = res_map[qs_resolution]

        if st.button("ğŸ¬ ã‚¹ãƒ©ã‚¤ãƒ‰ã‚·ãƒ§ãƒ¼ã‚’ç”Ÿæˆ", disabled=not qs_images):
            try:
                temp_dir = Path("temp/quick_slideshow")
                temp_dir.mkdir(parents=True, exist_ok=True)
                img_paths = []
                for uf in qs_images:
                    p = temp_dir / uf.name
                    with open(p, "wb") as f:
                        f.write(uf.getbuffer())
                    img_paths.append(p)

                out = (
                    Path("data/output")
                    / f"slideshow_{int(__import__('time').time())}.mp4"
                )
                # ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
                narration_segments = None
                enable_tts = False
                if enable_narr and narration_text.strip():
                    texts = _split_text_by_images(narration_text.strip(), len(img_paths))
                    seg_dur = float(qs_duration) / max(1, len(texts))
                    t = 0.0
                    narration_segments = []
                    for s in texts:
                        narration_segments.append({"text": s, "start": t, "duration": seg_dur})
                        t += seg_dur
                    enable_tts = True

                bgm_path = Path(selected_bgm_path) if selected_bgm_path else None

                with st.spinner("â³ ç”Ÿæˆä¸­..."):
                    out_path = generate_slideshow(
                        image_paths=img_paths,
                        output_path=out,
                        narration_segments=narration_segments,
                        bgm_path=bgm_path,
                        duration=float(qs_duration),
                        resolution=qs_res_tuple,
                        transition_advance=0.2,
                        pan_enabled=qs_pan,
                        pan_scale=float(qs_pan_scale),
                        enable_tts=enable_tts,
                    )
                st.success(f"âœ… ç”Ÿæˆå®Œäº†: {out_path}")
                st.video(str(out_path))
                with open(out_path, "rb") as vf:
                    st.download_button(
                        "ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        vf,
                        file_name=out_path.name,
                        mime="video/mp4",
                        key="dl_qs",
                    )
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                st.exception(e)

    with tab_exp:
        st.subheader("Explainer Slideshowï¼ˆãƒ†ã‚­ã‚¹ãƒˆâ†’å­—å¹•/TTSâ†’ã‚¹ãƒ©ã‚¤ãƒ‰ï¼‰")

        # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        default_text = (
            "ã‚¹ãƒˆãƒ¬ã‚¹ã§ãŠè…¹ãŒç—›ã„/èƒƒãŒé‡ã„èƒŒæ™¯ã«ã¯CRHãŒé–¢ä¸ã€‚å—å®¹ä½“I/IIã®ç™ºç¾ã«ã‚ˆã‚Šã€\n"
            "èƒƒã®é‹å‹•ã¯æŠ‘åˆ¶ã•ã‚Œã€å¤§è…¸ã®è •å‹•ã¯ä¿ƒé€²ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚æœã¯CRHãŒé«˜ãã€\n"
            "é€šå‹¤æ™‚ã®ã‚¹ãƒˆãƒ¬ã‚¹ã§ç—‡çŠ¶ãŒå‡ºã‚„ã™ã„ã€‚è©³ã—ãã¯æœ¬æ›¸ã§ã€‚æœ€å¾Œã«æ›¸å½±ã‚’ã”è¦§ãã ã•ã„ã€‚"
        )
        text_input = st.text_area(
            "èª¬æ˜ãƒ†ã‚­ã‚¹ãƒˆï¼ˆé•·æ–‡OKãƒ»è‡ªå‹•åˆ†å‰²ï¼‰",
            value=default_text,
            height=220,
            help="å¥èª­ç‚¹ã§è‡ªç„¶ã«åˆ†å‰²ã€‚ç”»åƒæšæ•°ã«åˆã‚ã›ã¦è‡ªå‹•èª¿æ•´ã—ã¾ã™ã€‚",
        )

        # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ or ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”Ÿæˆ
        st.markdown("---")
        st.caption("ç”»åƒã¯æœªç”¨æ„ã§ã‚‚OKã€‚ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã§è©¦ã›ã¾ã™ã€‚")
        uploaded_imgs = st.file_uploader(
            "è§£èª¬ç”¨ç”»åƒï¼ˆè¤‡æ•°å¯ï¼‰",
            type=["png", "jpg", "jpeg"],
            accept_multiple_files=True,
            key="expl_imgs",
        )
        cover_img = st.file_uploader(
            "æ›¸å½±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ»æœ€å¾Œã«é…ç½®ï¼‰",
            type=["png", "jpg", "jpeg"],
            key="expl_cover",
        )

        num_slides = st.slider(
            "ã‚¹ãƒ©ã‚¤ãƒ‰æšæ•°ï¼ˆæ›¸å½±é™¤ãï¼‰", min_value=3, max_value=12, value=5, step=1
        )
        total_images_preview = (len(uploaded_imgs) if uploaded_imgs else num_slides) + (
            1 if cover_img else 0
        )
        st.caption(f"æœ€çµ‚çš„ãªç”»åƒæšæ•°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {total_images_preview}æšï¼ˆæ›¸å½±å«ã‚€ï¼‰")

        duration = st.slider("å‹•ç”»ã®é•·ã•ï¼ˆç§’ï¼‰", 30, 180, 75, 5)
        enable_tts = st.checkbox("TTSã§éŸ³å£°ã‚‚ç”Ÿæˆï¼ˆæ¨å¥¨ï¼‰", value=True)

        final_title = st.text_input(
            "æœ€çµ‚ã‚¹ãƒ©ã‚¤ãƒ‰ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ›¸å½±ã«é‡ã­ã‚‹å­—å¹•ãƒ»ä»»æ„ï¼‰", value=""
        )

        # ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ææ¡ˆï¼ˆnanobanaå‘ã‘ï¼‰
        if st.button("ğŸ§  ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¡ˆã‚’è¡¨ç¤º"):
            segs = [
                s["text"]
                for s in build_narration_segments(
                    text_input or default_text,
                    num_slides + (1 if cover_img else 0),
                    duration,
                )
            ]
            st.markdown("**ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ã®ã‚¤ãƒ¡ãƒ¼ã‚¸æŒ‡ç¤ºï¼ˆä¾‹ï¼‰**")
            for i, s in enumerate(segs, 1):
                hint = (
                    "è¡¨ç´™ï¼ˆæ›¸å½±ï¼‰" if (cover_img and i == len(segs)) else "å†…å®¹ã‚¤ãƒ¡ãƒ¼ã‚¸"
                )
                st.text(f"[{i}] {hint}: {s[:80]}â€¦")
            st.info(
                "ã“ã®æ¡ˆã‚’åŸºã« nanobana ã§ç”»åƒã‚’ç”Ÿæˆã—ã€ä¸Šã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
            )

        # ç”Ÿæˆ
        if st.button("ğŸ¬ Explainer å‹•ç”»ã‚’ç”Ÿæˆ", disabled=not (text_input.strip())):
            try:
                # ç”»åƒã‚’ä¸€æ™‚ä¿å­˜ or ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”Ÿæˆ
                temp_dir = Path("temp/explainer")
                temp_dir.mkdir(parents=True, exist_ok=True)

                image_paths = []
                if uploaded_imgs and len(uploaded_imgs) > 0:
                    for uf in uploaded_imgs:
                        p = temp_dir / uf.name
                        with open(p, "wb") as f:
                            f.write(uf.getbuffer())
                        image_paths.append(p)
                    # è¶³ã‚Šãªã‘ã‚Œã°ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã§è£œå®Œ
                    while len(image_paths) < num_slides:
                        idx = len(image_paths) + 1
                        ph = temp_dir / f"placeholder_{idx}.png"
                        _make_placeholder(ph, idx)
                        image_paths.append(ph)
                    # å¤šã‘ã‚Œã°æŒ‡å®šæ•°ã«ä¸¸ã‚
                    image_paths = image_paths[:num_slides]
                else:
                    # ã™ã¹ã¦ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
                    for idx in range(1, num_slides + 1):
                        ph = temp_dir / f"placeholder_{idx}.png"
                        _make_placeholder(ph, idx)
                        image_paths.append(ph)

                cover_path = None
                if cover_img:
                    cover_path = temp_dir / ("cover_" + cover_img.name)
                    with open(cover_path, "wb") as f:
                        f.write(cover_img.getbuffer())

                with st.spinner("â³ ç”Ÿæˆä¸­... TTSæœ‰åŠ¹æ™‚ã¯éŸ³å£°é•·ã«åŒæœŸã—ã¾ã™"):
                    out = generate_explainer(
                        text=text_input or default_text,
                        images=image_paths,
                        add_cover=cover_path,
                        duration=duration,
                        enable_tts=enable_tts,
                        final_title=final_title.strip() or None,
                        output_dir=Path("data/output"),
                    )

                st.success(f"âœ… å‹•ç”»ç”Ÿæˆå®Œäº†: {out}")
                if Path(out).exists():
                    st.video(str(out))
                    with open(out, "rb") as vf:
                        st.download_button(
                            label="ğŸ“¥ å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=vf,
                            file_name=Path(out).name,
                            mime="video/mp4",
                            key="dl_expl",
                        )
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                st.exception(e)

    # --- Tab: Opening Animation ---
    with tab_open:
        st.subheader("Opening Animationï¼ˆå›è»¢ã‚ºãƒ¼ãƒ ãƒãƒƒã‚¯ï¼‰")
        up_img = st.file_uploader("ç”»åƒï¼ˆè¡¨ç´™ãªã©ï¼‰", type=["png","jpg","jpeg"], key="open_img")
        catch = st.text_input("ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ï¼ˆå­—å¹•/TTSç”¨ï¼‰", value="", key="open_catch")
        col1, col2, col3 = st.columns(3)
        with col1:
            open_duration = st.slider("é•·ã•(ç§’)", min_value=1.0, max_value=6.0, value=3.0, step=0.5, key="open_dur")
        with col2:
            zoom_start = st.slider("é–‹å§‹ã‚ºãƒ¼ãƒ ", min_value=1.0, max_value=3.0, value=1.5, step=0.1, key="open_zs")
        with col3:
            zoom_end = st.slider("çµ‚äº†ã‚ºãƒ¼ãƒ ", min_value=0.8, max_value=1.5, value=1.0, step=0.05, key="open_ze")
        use_tts = st.checkbox("TTSãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœ‰åŠ¹", value=False, key="open_tts")

        if st.button("ğŸ¬ Openingã‚’ç”Ÿæˆ", disabled=(up_img is None), key="open_btn"):
            try:
                temp_dir = Path("temp/opening"); temp_dir.mkdir(parents=True, exist_ok=True)
                img_path = temp_dir / up_img.name
                with open(img_path, "wb") as f:
                    f.write(up_img.getbuffer())
                out = Path("data/output") / f"opening_{int(__import__('time').time())}.mp4"
                with st.spinner("â³ ç”Ÿæˆä¸­..."):
                    vid = generate_opening_animation(
                        image_path=img_path,
                        output_path=out,
                        catchphrase=catch.strip() or None,
                        duration=float(open_duration),
                        zoom_start=float(zoom_start),
                        zoom_end=float(zoom_end),
                        enable_tts=use_tts,
                    )
                st.success(f"âœ… ç”Ÿæˆå®Œäº†: {vid}")
                st.video(str(vid))
                with open(vid, "rb") as vf:
                    st.download_button("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", vf, file_name=vid.name, mime="video/mp4", key="dl_open")
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                st.exception(e)

    # --- Tab: Overlay ---
    with tab_overlay:
        st.subheader("Overlayï¼ˆå‹•ç”»ã«è¡¨ç´™ç­‰ã‚’é‡ã­ã‚‹ï¼‰")
        up_vid = st.file_uploader("å…¥åŠ›å‹•ç”»", type=["mp4","mov","m4v"], key="ov_video")
        up_overlay = st.file_uploader("ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”»åƒ", type=["png","jpg","jpeg"], key="ov_img")
        col1, col2, col3 = st.columns(3)
        with col1:
            position = st.selectbox("é…ç½®", ["bottom","top","left","right","center"], index=0, key="ov_pos")
        with col2:
            ov_scale = st.slider("ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚µã‚¤ã‚º(é«˜ã•æ¯”)", min_value=0.1, max_value=0.9, value=0.35, step=0.05, key="ov_scale")
        with col3:
            anim = st.selectbox("ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³", ["float","static"], index=0, key="ov_anim")
        topbar = st.number_input("ä¸Šéƒ¨ç™½å¸¯(px)", min_value=0, max_value=400, value=0, key="ov_topbar")
        subtitle = st.text_input("ä¸Šéƒ¨å­—å¹•ï¼ˆä»»æ„ï¼‰", value="", key="ov_subtitle")

        if st.button("ğŸ¬ Overlayã‚’ç”Ÿæˆ", disabled=(up_vid is None or up_overlay is None), key="ov_btn"):
            try:
                tdir = Path("temp/overlay"); tdir.mkdir(parents=True, exist_ok=True)
                vpath = tdir / up_vid.name
                ipath = tdir / up_overlay.name
                with open(vpath, "wb") as f:
                    f.write(up_vid.getbuffer())
                with open(ipath, "wb") as f:
                    f.write(up_overlay.getbuffer())
                out = Path("data/output") / f"overlay_{int(__import__('time').time())}.mp4"
                with st.spinner("â³ åˆæˆä¸­..."):
                    vid = add_floating_overlay(
                        video_path=vpath,
                        output_path=out,
                        overlay_image_path=ipath,
                        position=position,
                        overlay_scale=float(ov_scale),
                        animation=anim,
                        top_bar_height=int(topbar),
                        subtitle_text=subtitle.strip() or None,
                    )
                st.success(f"âœ… ç”Ÿæˆå®Œäº†: {vid}")
                st.video(str(vid))
                with open(vid, "rb") as vf:
                    st.download_button("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", vf, file_name=vid.name, mime="video/mp4", key="dl_overlay")
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                st.exception(e)

    # --- Tab: Frame ---
    with tab_frame:
        st.subheader("Frameï¼ˆå‹•ç”»ã«ãƒ•ãƒ¬ãƒ¼ãƒ /è¡¨ç´™/ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿½åŠ ï¼‰")
        up_vid2 = st.file_uploader("å…¥åŠ›å‹•ç”»", type=["mp4","mov","m4v"], key="frm_video")
        title_txt = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«", value="", key="frm_title")
        author_txt = st.text_input("è‘—è€…ï¼ˆä»»æ„ï¼‰", value="", key="frm_author")
        up_cover = st.file_uploader("è¡¨ç´™ï¼ˆä»»æ„ï¼‰", type=["png","jpg","jpeg"], key="frm_cover")
        layout = st.selectbox("ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ", ["top_bottom"], index=0, key="frm_layout")

        if st.button("ğŸ¬ Frameã‚’ç”Ÿæˆ", disabled=(up_vid2 is None or not title_txt.strip()), key="frm_btn"):
            try:
                tdir = Path("temp/frame"); tdir.mkdir(parents=True, exist_ok=True)
                vpath = tdir / up_vid2.name
                with open(vpath, "wb") as f:
                    f.write(up_vid2.getbuffer())
                cpath = None
                if up_cover:
                    cpath = tdir / up_cover.name
                    with open(cpath, "wb") as f:
                        f.write(up_cover.getbuffer())
                out = Path("data/output") / f"framed_{int(__import__('time').time())}.mp4"
                with st.spinner("â³ åˆæˆä¸­..."):
                    vid = add_video_frame(
                        video_path=vpath,
                        output_path=out,
                        title=title_txt.strip(),
                        cover_image_path=cpath,
                        author=author_txt.strip() or None,
                        layout=layout,
                    )
                st.success(f"âœ… ç”Ÿæˆå®Œäº†: {vid}")
                st.video(str(vid))
                with open(vid, "rb") as vf:
                    st.download_button("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", vf, file_name=vid.name, mime="video/mp4", key="dl_frame")
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                st.exception(e)

    # --- Tab 4: Cover Card ---
    with tab_cov:
        st.subheader("Cover Cardï¼ˆè¡¨ç´™ï¼‹ã‚¿ã‚¤ãƒˆãƒ«ã®ç· ã‚ã‚«ãƒƒãƒˆï¼‰")

        cover_file = st.file_uploader(
            "è¡¨ç´™ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (PNG/JPG)",
            type=["png", "jpg", "jpeg"],
            key="cover_upl",
        )
        title_text = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆå­—å¹•ï¼‰", value="")
        subtitle_text = st.text_input(
            "ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¢å®š: ç¶šãã¯æœ¬æ›¸ã§ï¼‰", value="ç¶šãã¯æœ¬æ›¸ã§"
        )
        colA, colB, colC = st.columns(3)
        with colA:
            duration = st.slider("é•·ã•(ç§’)", min_value=2, max_value=6, value=3, step=1)
        with colB:
            y_offset = st.slider(
                "å­—å¹•ã®ä½ç½®(ä¸Šâ†’ä¸‹)", min_value=120, max_value=600, value=360, step=10
            )
        with colC:
            font_size = st.slider(
                "æ–‡å­—ã‚µã‚¤ã‚º", min_value=72, max_value=140, value=110, step=2
            )

        colD, colE = st.columns(2)
        with colD:
            use_tts = st.checkbox("TTSãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä»˜ã‘ã‚‹", value=True)
        with colE:
            tts_speed = st.slider(
                "è©±é€Ÿ", min_value=1.0, max_value=2.0, value=1.6, step=0.1
            )

        if st.button("ğŸ¬ Cover Card ã‚’ç”Ÿæˆ", disabled=(cover_file is None)):
            try:
                temp_dir = Path("temp/cover")
                temp_dir.mkdir(parents=True, exist_ok=True)
                cover_path = temp_dir / cover_file.name
                with open(cover_path, "wb") as f:
                    f.write(cover_file.getbuffer())

                narration_text = f"{title_text}ã€‚{subtitle_text}ã€‚" if use_tts else None

                with st.spinner("â³ ç”Ÿæˆä¸­..."):
                    out = generate_cover_card(
                        cover_image=cover_path,
                        title=title_text.strip() or None,
                        subtitle=subtitle_text.strip() or None,
                        duration=duration,
                        subtitle_position="top",
                        subtitle_fontsize=font_size,
                        subtitle_color=(255, 230, 0),
                        subtitle_y=y_offset,
                        narration_text=narration_text,
                        tts_speed=tts_speed,
                        output_path=None,
                    )

                st.success(f"âœ… å‹•ç”»ç”Ÿæˆå®Œäº†: {out}")
                if Path(out).exists():
                    st.video(str(out))
                    with open(out, "rb") as vf:
                        st.download_button(
                            label="ğŸ“¥ å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=vf,
                            file_name=Path(out).name,
                            mime="video/mp4",
                            key="dl_cover",
                        )
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                st.exception(e)

    # --- Tab 5: Text to Image backends ---
    with tab_img:
        st.subheader("Text to Imageï¼ˆnanobana / Geminiï¼‰")

        sub_tab1, sub_tab2 = st.tabs(["nanobana CLI", "Gemini API"])

        # nanobana CLI backend
        with sub_tab1:
            nanobana_cmd = os.getenv("NANOBANA_CMD")
            if nanobana_cmd:
                st.success("âœ… NANOBANA_CMD è¨­å®šæ¸ˆã¿: å®Ÿç”»åƒã‚’ç”Ÿæˆã—ã¾ã™")
                with st.expander("ç¾åœ¨ã®ã‚³ãƒãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ", expanded=False):
                    st.code(nanobana_cmd)
            else:
                st.warning(
                    "âš ï¸ NANOBANA_CMD æœªè¨­å®š: ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒã§å‹•ä½œç¢ºèªã—ã¾ã™"
                )

            default_prompts = "\n".join(
                [
                    "æœã®ã‚¸ãƒ§ã‚®ãƒ³ã‚°ã€è‡ªç„¶å…‰ã€çˆ½ã‚„ã‹ã€å†™çœŸé¢¨ã€ç¸¦é•·1080x1920ã€ä½™ç™½å¤šã‚ã€è¢«å†™ä½“ã¯åŒ¿å",
                    "å®¤å†…ã‚¹ãƒˆãƒ¬ãƒƒãƒã€ã‚„ã‚ã‚‰ã‹ã„æ—¥å·®ã—ã€å†™çœŸé¢¨ã€è½ã¡ç€ã„ãŸé…è‰²ã€æ¸…æ½”æ„Ÿ",
                    "ã‚¦ã‚©ãƒ¼ã‚­ãƒ³ã‚°ã€ç·‘é“ã€æ—©æœã€å†™çœŸé¢¨ã€ãƒŸãƒ‹ãƒãƒ«æ§‹å›³",
                    "è»½ã„ç­‹ãƒˆãƒ¬ï¼ˆè‡ªé‡ï¼‰ã€è‡ªå®…ã®ãƒªãƒ“ãƒ³ã‚°ã€å†™çœŸé¢¨ã€æ•´ã£ãŸèƒŒæ™¯ã€é›‘å¤šãªç‰©ã¯æ˜ ã‚‰ãªã„",
                ]
            )

            prompts_text = st.text_area(
                "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆ1è¡Œ=1ç”»åƒï¼‰",
                value=default_prompts,
                height=160,
                help="å„è¡ŒãŒ1æšã®ç”Ÿæˆå¯¾è±¡ã«ãªã‚Šã¾ã™ã€‚ãƒ†ã‚¤ã‚¹ãƒˆçµ±ä¸€ãªã‚‰å‰ç½®ãã‚’æƒãˆã¦ãã ã•ã„ã€‚",
                key="nanobana_prompts",
            )

            out_base = Path("data/generated/nanobana")
            import time as _t

            subdir = out_base / str(int(_t.time()))

            if st.button("ğŸ–¼ï¸ ç”»åƒã‚’ç”Ÿæˆ (nanobana)"):
                try:
                    prompt_list = [
                        ln.strip()
                        for ln in (prompts_text or "").splitlines()
                        if ln.strip()
                    ]
                    if not prompt_list:
                        st.error("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’1è¡Œä»¥ä¸Šå…¥åŠ›ã—ã¦ãã ã•ã„")
                    else:
                        client = NanobanaClient()
                        with st.spinner("â³ ç”Ÿæˆä¸­..."):
                            paths = client.generate_images(prompt_list, out_dir=subdir)
                        st.success(f"âœ… ç”Ÿæˆå®Œäº†: {len(paths)}æš â†’ {subdir}")

                        cols = st.columns(2)
                        for i, p in enumerate(paths):
                            with cols[i % 2]:
                                st.image(
                                    str(p), caption=p.name, use_container_width=True
                                )
                        st.info(
                            "Explainerã‚¿ãƒ–ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€ãã®ã¾ã¾å‹•ç”»åŒ–ã§ãã¾ã™"
                        )
                except Exception as e:
                    st.error(f"âŒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                    st.exception(e)

        # Gemini API backend
        with sub_tab2:
            st.caption("Gemini 2.5 Flash Image ã‚’ä½¿ç”¨ï¼ˆGOOGLE_API_KEYãŒå¿…è¦ï¼‰")
            g_prompt = st.text_area(
                "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                value="A realistic photo of a Shiba Inu sitting on a wooden floor, vertical 1080x1920, natural light, clean background",
                height=100,
                key="gemini_prompt",
            )
            g_n = st.slider(
                "ç”Ÿæˆæšæ•°", min_value=1, max_value=4, value=1, step=1, key="gemini_n"
            )
            g_model = st.text_input(
                "ãƒ¢ãƒ‡ãƒ«", value="gemini-2.5-flash-image", key="gemini_model"
            )

            out_dir = Path("data/generated/gemini")
            if st.button("ğŸ–¼ï¸ ç”»åƒã‚’ç”Ÿæˆ (Gemini)"):
                try:
                    with st.spinner("â³ ç”Ÿæˆä¸­..."):
                        paths = gemini_generate_images(
                            prompt=g_prompt.strip(),
                            n=g_n,
                            model=g_model.strip() or "gemini-2.5-flash-image",
                            output_dir=out_dir,
                        )
                    if paths:
                        st.success(f"âœ… ç”Ÿæˆå®Œäº†: {len(paths)}æš â†’ {out_dir}")
                        cols = st.columns(2)
                        for i, p in enumerate(paths):
                            with cols[i % 2]:
                                st.image(
                                    str(p), caption=p.name, use_container_width=True
                                )
                        st.info(
                            "Explainerã‚¿ãƒ–ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€ãã®ã¾ã¾å‹•ç”»åŒ–ã§ãã¾ã™"
                        )
                    else:
                        st.warning(
                            "ç”»åƒãƒ‘ãƒ¼ãƒˆãŒè¿”ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¨©é™ãƒ»ã‚¯ã‚©ãƒ¼ã‚¿ãƒ»ãƒ¢ãƒ‡ãƒ«æŒ‡å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚"
                        )
                except Exception as e:
                    st.error(f"âŒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                    st.exception(e)

    # --- Tab 6: Concat Videos ---
    with tab_concat:
        st.subheader("Concat Videosï¼ˆè¤‡æ•°å‹•ç”»ã‚’é †ç•ªã«é€£çµï¼‰")

        uploaded_videos = st.file_uploader(
            "å‹•ç”»ã‚’é¸æŠï¼ˆè¤‡æ•°ï¼‰", type=["mp4", "mov", "m4v"], accept_multiple_files=True
        )

        # ä¸¦ã³é †ç®¡ç†
        order_key = "concat_order"
        if uploaded_videos:
            if order_key not in st.session_state or len(
                st.session_state[order_key]
            ) != len(uploaded_videos):
                st.session_state[order_key] = list(range(len(uploaded_videos)))

            st.caption("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é †ã§åˆæœŸåŒ–ã€‚ä¸Šä¸‹ãƒœã‚¿ãƒ³ã§ä¸¦ã³æ›¿ãˆå¯èƒ½ã§ã™ã€‚")
            ordered = [uploaded_videos[i] for i in st.session_state[order_key]]
            for idx, uf in enumerate(ordered):
                c1, c2, c3 = st.columns([6, 1, 1])
                with c1:
                    st.text(f"{idx + 1}. {uf.name}")
                with c2:
                    if st.button("â†‘", key=f"concat_up_{idx}", disabled=(idx == 0)):
                        o = st.session_state[order_key]
                        o[idx], o[idx - 1] = o[idx - 1], o[idx]
                        st.rerun()
                with c3:
                    if st.button(
                        "â†“", key=f"concat_dn_{idx}", disabled=(idx == len(ordered) - 1)
                    ):
                        o = st.session_state[order_key]
                        o[idx], o[idx + 1] = o[idx + 1], o[idx]
                        st.rerun()

        st.markdown("---")
        cA, cB, cC = st.columns(3)
        with cA:
            fps = st.number_input("å‡ºåŠ›FPS", min_value=1, max_value=120, value=24)
        with cB:
            res_text = st.text_input("è§£åƒåº¦ (ä¾‹: 1080x1920)", value="1080x1920")
        with cC:
            method = st.selectbox("é€£çµæ–¹æ³•", options=["compose", "chain"], index=0)

        def _parse_res(txt: str):
            try:
                w, h = txt.lower().split("x")
                return int(w), int(h)
            except Exception:
                return None

        if st.button("ğŸ¬ é€£çµã—ã¦æ›¸ãå‡ºã™", disabled=not uploaded_videos):
            try:
                temp_dir = Path("temp/concat")
                temp_dir.mkdir(parents=True, exist_ok=True)
                paths = []
                for i in st.session_state.get(order_key, []):
                    uf = uploaded_videos[i]
                    p = temp_dir / uf.name
                    with open(p, "wb") as f:
                        f.write(uf.getbuffer())
                    paths.append(p)

                out_dir = Path("data/output")
                out_dir.mkdir(parents=True, exist_ok=True)
                import time as _t

                out = out_dir / f"merged_{int(_t.time())}.mp4"

                res = _parse_res(res_text.strip()) if res_text.strip() else None
                with st.spinner("â³ é€£çµä¸­..."):
                    merged = concat_videos(
                        inputs=paths,
                        output=out,
                        fps=int(fps) if fps else None,
                        resolution=res,
                        method=method,
                    )

                st.success(f"âœ… é€£çµå®Œäº†: {merged}")
                if merged.exists():
                    st.video(str(merged))
                    with open(merged, "rb") as vf:
                        st.download_button(
                            label="ğŸ“¥ å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=vf,
                            file_name=merged.name,
                            mime="video/mp4",
                            key="dl_concat",
                        )
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                st.exception(e)


def _make_placeholder(path: Path, idx: int, size=(1080, 1920)):
    """ç°¡æ˜“ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”»åƒã‚’ä½œæˆ"""
    img = Image.new("RGB", size, (30, 30, 40))
    draw = ImageDraw.Draw(img)
    try:
        font = ImageFont.truetype(
            "/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W6.ttc", 140
        )
    except:
        font = ImageFont.load_default()
    text = f"Slide {idx}"
    tw, th = draw.textbbox((0, 0), text, font=font)[2:4]
    x = (size[0] - tw) // 2
    y = (size[1] - th) // 2
    # å½±
    draw.text((x + 4, y + 4), text, font=font, fill=(0, 0, 0))
    draw.text((x, y), text, font=font, fill=(230, 230, 240))
    img.save(path)


if __name__ == "__main__":
    main()
